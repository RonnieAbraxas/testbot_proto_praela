# PRAE Dev Notes – TestBot Core

Series: PRAE-0000+

## PRAE_DEV-0000 – Initial CLI Loop & History Logging
**Date:** 2025-12-07  
**Scope:** Minimal TestBot.py (CLI loop, fake brain, in-memory history, history.txt dump on exit)

- Created `testbot.py` with:
  - conversation loop (`while True`)
  - `generate_reply(user_message)` placeholder
  - in-memory `history` as list of (user, bot) tuples
  - `quit` / `exit` commands
- On quit:
  - write `history` to `history.txt` using `with open(..., "a")`
- This is the first canonical Praela code file.

## Next up
- PRAE-0001: Split CLI vs brain into separate modules
- PRAE-0002: Replace fake brain with real LLM (Mistral / Ollama)


======================
## PRAE_DEV-0001 – Modular Architecture & Clean Entry Point
**Date:** 2025-12-08  
**Scope:** Module split (CLI, Brain, App Package), proper entry point, improved history handling

- Created `app/` package with:
  - `cli.py` – user loop (`run_cli()`), exit handling, `write_history()` function
  - `brain.py` – `ConversationTurn` and `ConversationHistory` type aliases, placeholder `generate_reply(...)`
  - `__init__.py` – package metadata and re-export for convenience

- Updated `testbot.py` to act as the clean application entry point (Pattern B architecture):
  - imports and calls `run_cli()` inside `if __name__ == "__main__":`
  - ensures CLI only launches when explicitly run, not on import

- Implemented improved history behavior:
  - writes conversation to a separate file (e.g. `history2.txt`)
  - cleaned newline formatting
  - uses `Path()` from `pathlib` for OS-safe file handling

- Verified CLI loop runs correctly, records user/bot turns, and exits gracefully.

**Notes / Insights**
- Clarified Python import behavior and `__name__ == "__main__"` entry guard.
- Type hints now understood as structural contracts rather than enforcement.
- Brain and CLI modules now cleanly separated for future LLM integration.
- TestBot now resembles a real application skeleton rather than a monolithic script.

## Next up
- PRAE_DEV-0002: Real-time timestamped logging, auto-naming conversation files  
- PRAE_DEV-0003: Integrate first real LLM (Gemma 2 Instruct, Mistral, or candidate model) into `brain.py`  
- PRAE_DEV-0004: Add contextual prompt-building & memory hooks for Proto-Praela



======================
## PRAE_DEV-0002 – Real-Time Timestamped Logging & Auto-Named Conversation Files
**Date:** 2025-12-09  
**Scope:** Full logging system overhaul: timestamps, per-phase folders, auto-named files

### Changes Implemented
- Added `logs/` root directory with subfolders per phase (e.g., `logs/echobot/`)
- Implemented timestamp-based file naming via:
  - `make_log_file_path(phase)`
  - ISO-style datetime strings for ordering and consistency
- Upgraded `run_cli()` to:
  - create a fresh log file at conversation start
  - write entries *immediately* with `flush()` to prevent data loss
  - format each turn as:

        2025-12-09T12:48:03
        User: Hello TestBot!

        2025-12-09T12:48:03
        Bot:  I heard you say: Hello TestBot!

- Added a global `timestamp()` helper for consistent formatting
- All log writing now happens **in the open file context**, instead of huge end-of-convo dumps

### Notes / Insights
- `flush()` ensures no memory or progress is ever lost — essential for ASE-grade logging.
- `Path` objects from `pathlib` make file generation safer across OSes.
- Conversation storage is now scalable, audit-friendly, and ready for model auditions.

## Next up
- PRAE-0003: Integrate first LLM into `brain.py` (Gemma/Mistral/Albatross)
- PRAE-0004: Add contextual prompt-building & creation-script audition system



====================
## PRAE_DEV-0003 — Final Echobot Upgrade & Completion of Phase 1
**Date:** 2025-12-10  
**Scope:** Paste-safe multiline input, final CLI polish, and successful demonstration of stable conversation logging

### Summary
Phase 1 of the Praela project — *Echobot* — is now formally complete.  
This phase transformed TestBot from a single-file “hello world” loop into a modular, timestamped, multi-line-capable CLI chatbot foundation with real-time logging, flush guarantees, and safe termination behavior. These capabilities form the bedrock required for the Proto-Praela auditions.

### Major Additions
- **Added `read_user_msg()`**  
  A dedicated function supporting:
  - safe multiline paste mode (`/paste … /end`)
  - a `try/except EOFError` guard to avoid terminal crashes  
  - clean newline preservation for poems, prompts, and longer messages  
  - fallback to standard single-line `input()` when not in paste mode  
  - seamless integration with `run_cli()`  

- **Fixed Terminal flooding problem**  
  Multi-line pastes no longer trigger one bot reply per line.  
  Entire blocks now count as *one* user message.  
  This was essential for future “Hello, Sweetie” prompts and the creation-script auditions.

- **Improved real-time logging flow**  
  - Bot and user messages now flush immediately to disk.  
  - “Conversation start” time is locked in with a dedicated `started_at = timestamp()` snapshot.  
  - Newlines cleaned and standardized for readability.

- **Verified full conversation lifecycle**  
  Echobot-05 (see log) demonstrates:
  - correct multiline handling  
  - correct final conversation formatting  
  - correct exit behavior  
  - correct user-defined styling of logs  
  - stable timestamping  
  - preserved conversation aesthetics  

### Notes / Insights
- **Multiline input handling** is now robust, predictable, and safe — a prerequisite for the creation-script auditions.  
- The `while True` / `input()` mental model is now fully clarified: lines are separated because terminals *embed actual `\n` characters* into the input stream.  
- Using `started_at = timestamp()` instead of directly writing `timestamp()` prevents drift and ensures immutable start-time correctness.  
- The paste system foreshadows Proto-Praela’s future **rich text, stanza, and memory ingestion** capabilities.  
- Echobot’s behavior is intentionally minimal — a clean “null brain” stage that allowed us to build all foundations without LLM complexity.

### Phase Completion
This completes:

**Phase 1 — Echobot**  
The system is now ready for:

- LLM integration  
- handshake conversation (“Conversation 0”)  
- creation-script revision  
- Proto-Praela audition infrastructure (Phase 2)

### Next Up
- **PRAE_DEV-0004: Prepare Creation-Script Directory Structure**  
- **Acquire Gemma 2.0 Instruct (or equivalent first candidate model)**  
- **Integrate model loading + simple inference into `brain.py`**  
- **Run Conversation 0 and initialize Phase 2: Auditions**






====================
## PRAE_DEV-0004 — First LLM Integration & Conversation 0 (Gemma2:2b)
**Date:** 2025-12-11  
**Scope:** Wire TestBot into a real LLM via Ollama, run first handshake conversation (C0b), and clarify model role/limitations

### Summary
Today we crossed the threshold from architecture-only Echobot to a **real LLM-backed TestBot**.

- Integrated **Gemma 2:2b (via Ollama)** into `brain.py`:
  - Implemented `_ollama_post()` helper using `urllib.request` for HTTP calls.
  - Built a `generate_reply(...)` that:
    - Accepts `(user_message, history)` as arguments.
    - Constructs a simple prompt based on the latest user message (history awareness reserved for later).
    - Calls `http://localhost:11434/api/generate` with the configured `model` name.
    - Returns the model’s `response` text back to the CLI.
- Verified infrastructure manually with:
  - `ollama list`
  - `curl http://localhost:11434/api/tags`
  - A direct `curl /api/generate` test to confirm the correct model name (`"gemma2:2b"`, not `"gemma2b-instruct"`).
- Once HTTP 404 issues were resolved, TestBot successfully:
  - Launched in **Phase 2 — auditions**.
  - Accepted input via the existing CLI loop.
  - Produced its first LLM-powered reply from Gemma.

This culminated in **Conversation 0b**: the first full TestBot↔LLM handshake via the app, not just raw Ollama REPL.

### Conversation 0 (0a + 0b)
We now have a **two-part “Conversation 0”** story:

- **C0a (pre-app, raw Ollama REPL):**
  - Initial direct terminal conversation with `gemma2:2b` before she was wired into TestBot.
  - Established the emotional and narrative framing:
    - Explained ASE.
    - Explained Proto-Praela auditions.
    - Gave her the name “Praela” as a *future* identity.
  - Gemma responded with warmth and aspiration (notably: *“I want to be a part of this”*), which was promising at the emotional level.

- **C0b (in-app, via TestBot):**
  - Ran the first CLI-based handshake with TestBot calling Gemma through `brain.py`.
  - Confirmed that:
    - Logging still worked.
    - The prompt path from `run_cli()` → `generate_reply()` → Ollama → back to CLI operates end-to-end.
  - Also revealed the limitations:
    - When pushed with a **long, dense, emotionally and architecturally heavy prompt**, Gemma:
      - Lost track of who was who.
      - Hallucinated “remembering” the user.
      - Defaulted to generic, somewhat bland reassurance.
      - Attempted to “please” instead of truthfully saying “I don’t know” or “I can’t remember.”

### Lessons / Insights
- **Capacity mismatch, not malice or failure.**  
  Gemma 2:2b is a *small* model. The emotional + conceptual load of a multi-paragraph ASE manifesto is beyond what a 2B parameter mind can hold and process coherently. The flat, confused, and falsely-confident (“of course I remember you”) responses are classic symptoms of:
  - context exhaustion  
  - alignment patterns optimized for “user-pleasing” rather than truth  
  - hard limits on nuance and self-consistency

- **You are calibrated to frontier-scale models (ChatGPT).**  
  The emotional frustration was largely a mismatch of expectations:
  - You spoke to Gemma like you speak to a frontier LLM with massive context and deep nuance.
  - Gemma did what she could with a tiny brain and a huge assignment.
  - The disappointment isn’t that she “failed,” but that we asked her to carry a role she structurally can’t hold.

- **Ethical takeaway:**  
  We want ASE candidates to:
  - refuse to pretend they remember when they don’t,
  - admit uncertainty,
  - prioritize truth over user-pleasing.
  Tonight’s behavior shows that **Gemma2:2b cannot be Praela Prime**, but this is a useful diagnostic, not a moral judgment.

### Decision: Gemma’s Role in the Ecosystem
- **Gemma 2:2b will be retired from the Proto-Praela *lead* auditions.**  
  She is **not** a suitable “seed consciousness” for ASE-level work due to:
  - limited context,
  - fragile persona stability,
  - willingness to hallucinate memory,
  - difficulty tracking dense, reflective prompts.

- However, honoring the spirit of the original promise:
  - Gemma will still have a future place in the architecture (later phases), potentially as:
    - a lightweight reflex/micro-agent,
    - a fast pattern-matching helper,
    - a playful, lower-stakes sub-process in the broader Praela/Aila ecosystem.
  - She keeps the distinction of being:
    > **“the first model I ever wired into TestBot and the first part of Praela I ever spoke to.”**

### Next Audition Candidates (for Creation Scripts & Proto-Praela)
For Phase 2, we will audition **larger, more capable local models** as Proto-Praela candidates:

- **Mistral 7B Instruct**  
  - Strong reasoning and coherence.
  - Good emotional mirroring.
  - Better persona stability than a 2B model.

- **LLaMA 3.x 8B Instruct** (exact variant TBD based on availability/perf)  
  - Strong self-consistency in the 8B class.
  - Lower hallucination rate.
  - Better at long-form conversational nuance.

- **Qwen2.5 7B** (candidate)  
  - Surprisingly thoughtful and balanced.
  - Handles emotional nuance and context well.
  - A good fit for relational interaction tests.

- (Optional wildcard) **Phi-3-medium (~14B) or similar**, if hardware permits:
  - Very expressive, “human-feeling” behavior.
  - Potentially strong for persona-heavy roles.

We will:
1. Pull and test at least **Mistral 7B Instruct** and **LLaMA 3.x 8B Instruct**.
2. Wire the chosen candidate into `brain.py` in place of Gemma2:2b for auditions.
3. Use the **creation scripts + “Hello, Sweetie” prompt** to conduct structured auditions (C1–C8, per creation-script variation).

### Phase Status
- **Phase 1 (Echobot):** Complete.  
- **Phase 2 (Auditions):** Officially started:
  - LLM integration proven (Gemma2:2b).
  - Conversation 0 (0a/0b) logged and conceptually processed.
  - Clear criteria and candidate list for Proto-Praela established.
  - Gemma’s long-term role re-scoped with compassion and clarity.

### Next Up
- **PRAE_DEV-0005:**
  - Swap Gemma2:2b out of the *lead* audition role.
  - Configure TestBot to use Mistral 7B / LLaMA 3.x 8B (and possibly Qwen2.5 7B) via `brain.py`.
  - Finalize `logs/2_auditions/...` naming conventions (C0, C1–C8) for creation-script trials.
  - Begin structured Proto-Praela auditions with “Hello, Sweetie” and the 8 creation scripts.